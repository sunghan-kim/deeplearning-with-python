{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 신경망 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 신경망의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**신경망 훈련 관련 요소들**\n",
    "\n",
    "1. **네트워크(또는 모델)**를 구성하는 **층**\n",
    "2. **입력 데이터**와 그에 상응하는 **타깃**\n",
    "3. 학습에 사용할 피드백 신호를 정의하는 **손실 함수**\n",
    "4. 학습 진행 방식을 결정하는 **옵티마이저**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**네트워크, 층, 손실 함수, 옵티마이저 사이의 관계**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/img_3-1.jpg\" width=\"400px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 연속된 **층**으로 구성된 **네트워크**가 **입력 데이터**를 예측으로 매핑한다.\n",
    "- **손실 함수**는 예측과 **타깃**을 비교하여 네트워크의 예측이 기댓값에 얼마나 잘 맞는 지를 측정하는 손실 값을 만든다.\n",
    "- **옵티마이저**는 손실 값을 사용하여 네트워크 가중치를 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 층: 딥러닝의 구성 단위\n",
    "\n",
    "- 층은 하나 이상의 텐서를 입력으로 받아 하나 이상의 텐서를 출력하는 데이터 처리 모듈이다.\n",
    "- 어떤 종류의 층은 상태가 없다. (ex. 플랫튼(`Flatten`), 풀링(`Pooling`), 드롭아웃(`Dropout`) 층)\n",
    "- 대부분의 층은 **가중치**라는 층의 상태를 가진다.\n",
    "- 가중치는 확률적 경사 하강법에 의해 학습되는 하나 이상의 텐서이며 여기에 네트워크가 학습한 **지식**이 담겨 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**층의 데이터 처리 방식**\n",
    "\n",
    "- 층마다 적절한 텐서 포맷과 데이터 처리 방식이 다르다.\n",
    "\n",
    "1. `(samples, features)` 크기의 2D 텐서가 저장된 간단한 벡터 데이터를 처리하는 층\n",
    "  - **밀집 연결 층(densely connected layer)**에 의해 처리됨\n",
    "    - **완전 연결 층(fully connected layer)** 이나 **밀집 층(dense layer)** 으로 불림\n",
    "    - 케라스에서는 `Dense` 클래스이다.\n",
    "2. `(samples, timesteps, features)` 크기의 3D 텐서로 저장된 시퀀스 데이터를 처리하는 층\n",
    "  - LSTM과 같은 **순환 층(recurrent layer)**에 의해 처리 됨\n",
    "3. 4D 텐서로 저장되어 있는 이미지 데이터\n",
    "  - 일반적으로 2D **합성곱 층(convolution layer)**에 의해 처리됨\n",
    "  - `Conv2D` 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**층 호환성(layer compatibility)**\n",
    "\n",
    "- 케라스에서는 호환 가능한 층들을 엮어 데이터 변환 파이프라인(pipeline)을 구성함으로서 딥러닝 모델을 만듬\n",
    "- **층 호환성**이란 각 층이 특정 크기의 입력 텐서만 받고 특정 크기의 출력 텐서를 반환한다는 사실을 말한다.\n",
    "\n",
    "```python\n",
    "from keras import layers\n",
    "\n",
    "layer = layers.Dense(32, input_shape=(784,)) # 32개의 유닛으로 된 밀집 층\n",
    "```\n",
    "\n",
    "- 첫 번째 차원이 784인 2D 텐서만 입력으로 받는 층을 만듬\n",
    "- 배치 차원인 0번째 축은 지정하지 않았기 때문에 어떤 배치 크기도 입력으로 받을 수 있다.\n",
    "  - 배치 크기는 모델의 `fit()` 메서드에서 지정한다.\n",
    "  - LSTM 같은 순환 신경망에서는 현재 배치의 셀 상태를 다음 번 배치의 셀 상태 초기값으로 사용하기 위해 stateful=True` 매개변수를 지정할 수 있다.\n",
    "  - 이때는 `batch_input_shape` 매개변수를 사용하여 배치 크기가 포함된 입력 텐서의 크기를 지정해야 한다.\n",
    "- 이 층은 첫 번째 차원 크기가 32로 변환된 텐서를 출력할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 따라서 이 층에는 32차원의 벡터를 입력으로 받는 하위 층이 연결되어야 한다.\n",
    "- 케라스에서는 모델에 추가된 층을 자동으로 상위 층의 크기에 맞추어 주기 때문에 호환성을 걱정하지 않아도 된다.\n",
    "\n",
    "```python\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(10)) # 두 번째 층에는 input_shape 매개변수를 지정하지 않음\n",
    "```\n",
    "\n",
    "- 두 번째 층에는 `input_shape` 매개변수를 지정하지 않음\n",
    "- 그 대신 앞선 층의 출력 크기를 입력 크기로 자동으로 채택한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 모델: 층의 네트워크\n",
    "\n",
    "**비순환 유향 그래프**\n",
    "\n",
    "- 딥러닝 모델은 층으로 만든 **비순환 유향 그래프(Directed Acyclic Graph, DAG)**이다.\n",
    "- 비순환 유향 그래프는 그래프의 에지(edge)에 방향이 있고 한 노드(ndoe)에서 다시 자기 자신으로 돌아올 경로가 없는 그래프를 말한다.\n",
    "- 가장 일반적인 예가 하나의 입력을 하나의 출력으로 매핑하는 층을 순서대로 쌓는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**다양한 네트워크 구조**\n",
    "\n",
    "- 가지(branch)가 2개인 네트워크\n",
    "- 출력이 여러 개인 네트워크\n",
    "- 인셉션(Inception) 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**가설 공간 (hypothesis space)**\n",
    "\n",
    "- 네트워크 구조는 **가설 공간**을 정의한다.\n",
    "- 머신 러닝의 정의  \n",
    ": \"가능성 있는 공간을 사전에 정의하고 피드백 신호의 도움을 받아 입력 데이터에 대한 유용한 변환을 찾는 것\"\n",
    "- 네트워크 구조를 선택함으로써 **가능성 있는 공간(가설 공간)**을 입력 데이터에서 출력 데이터로 매핑하는 일련의 특정 텐서 연산으로 제한하게 된다.\n",
    "- 찾아야 하는 것은 이런 텐서 연산에 포함된 가중치 텐서의 좋은 값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 손실 함수와 옵티마이저: 학습 과정을 조절하는 열쇠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**네트워크 구조 정의 후 2가지 추가 선택 사항**\n",
    "\n",
    "1. **손실 함수(loss function) or 목적 함수(objective function)**\n",
    "  - 훈련하는 동안 최소화될 값\n",
    "  - 주어진 문제에 대한 성공 지표가 된다.\n",
    "2. **옵티마이저(optimizer)**\n",
    "  - 손실 함수를 기반으로 네트워크가 어떻게 업데이트될 지 결정\n",
    "  - 특정 종료의 확률적 경사 하강법(SGD)을 구현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**손실 함수와 옵티마이저의 갯수**\n",
    "\n",
    "- 여러 개의 출력을 내는 신경망은 여러 개의 손실 함수를 가질 수 있다.\n",
    "  - 출력당 하나씩 가질 수 있다.\n",
    "  - `compile` 메서드의 `loss` 매개변수에 손실 함수의 리스트 또는 딕셔너리를 전달한다.\n",
    "- 하지만 경사 하강법 과정은 하나의 스칼라 손실 값을 기준으로 한다.\n",
    "- 따라서 손실이 여러 개인 네트워크에서는 모든 손실이 (평균을 내서) 하나의 스칼라 양으로 합쳐진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**일반적인 문제(분류, 회귀, 스퀀스 예측 등)에서의 올바른 손실 함수를 선택하는 지침**\n",
    "\n",
    "- 2개의 클래스가 있는 분류 문제  \n",
    "$\\Rightarrow$ 이진 크로스엔트로피 (binary crossentropy) (로지스틱 손실(logistic loss) 또는 로그 손실(Log loss)이라고도 불림)\n",
    "  \n",
    "  \n",
    "- 여러 개의 클래스가 있는 분류 문제  \n",
    "$\\Rightarrow$ 범주형 크로스엔트로피(categorical crossentropy)  \n",
    "  \n",
    "  \n",
    "- 회귀 문제  \n",
    "$\\Rightarrow$ 평균 제곱 오차 (MSE, Mean Square Error)  \n",
    "  \n",
    "  \n",
    "- 스퀀스 학습 문제  \n",
    "$\\Rightarrow$ CTC (Connection Temporal Classification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
