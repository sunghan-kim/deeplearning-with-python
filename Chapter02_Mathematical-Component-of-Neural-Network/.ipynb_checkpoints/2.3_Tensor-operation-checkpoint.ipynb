{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 신경망의 수학적 구성 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 신경망의 톱니바퀴: 텐서 연산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텐서 연산(tensor operation)**\n",
    "\n",
    "- 심층 신경망이 학습한 모든 변환을 수치 데이터 텐서에 적용하는 연산\n",
    "- ex) 텐서 덧셈, 텐서 곱셈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**케라스 층 생성**\n",
    "\n",
    "```python\n",
    "keras.layers.Dense(512, activation='relu')\n",
    "```\n",
    "\n",
    "- 이 층은 2D 텐서를 입력으로 받고 입력 텐서의 새로운 표현인 또 다른 2D 텐서를 반환하는 함수처럼 해석 가능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**함수의 구체적인 표현**\n",
    "\n",
    "```python\n",
    "output = relu(dot(W, input) + b)\n",
    "```\n",
    "\n",
    "- `W` : 2D 텐서\n",
    "- `b` : 벡터\n",
    "- `W`, `b` 모두 층의 속성이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3개의 텐서 연산**\n",
    "\n",
    "- 위 함수에는 3개의 텐서 연산이 있다.\n",
    "\n",
    "1. **`dot(W, input)`**\n",
    "  - 입력 텐서(`x`)와 텐서 `W` 사이의 **점곱(dot)**  \n",
    "  \n",
    "  \n",
    "2. **`dot(W, input) + b`**\n",
    "  - 점곱의 결과인 2D 텐서(`dot(W, input)`)와 벡터 `b` 사이의 **덧셈(+)**  \n",
    "  \n",
    "  \n",
    "3. **`relu(dot(W, input) + b)`**\n",
    "  - relu(렐루) 연산\n",
    "  - `relu(x) = max(x, 0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 원소별 연산 (element-wise operation)\n",
    "\n",
    "- 텐서에 있는 각 원소에 독립적으로 적용됨\n",
    "- 즉, 고도의 병렬 구현이 가능한 연산이라는 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**relu 연산 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 # x는 2D 넘파이 배열이다.\n",
    "    \n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**덧셈 연산 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2 # x와 y는 2D 넘파이 배열이다.\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy() # 입력 텐서를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**넘파이 내장 함수**\n",
    "\n",
    "- 넘파이 배열을 다룰때는 최적화된 넘파이 내장 함수로 이런 연산들을 처리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  6]\n",
      " [-2 -2]] \n",
      "\n",
      "[[6. 6.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([[2,2],\n",
    "              [3,3]])\n",
    "y = np.array(([4,4],\n",
    "              [-5,-5]))\n",
    "\n",
    "z = x + y # 원소별 덧셈\n",
    "print(z, '\\n')\n",
    "\n",
    "z = np.maximum(z, 0.) # 원소별 렐루 함수\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 브로드캐스팅 (broadcasting)\n",
    "\n",
    "- 크기가 다른 두 텐서 사이의 연산을 할 경우 모호하지 않고 실행 가능하다면 작은 텐서가 큰 텐서의 크기에 맞추어 **브로드캐스팅(broadcasting)**된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**브로드캐스팅의 2단계**\n",
    "\n",
    "1. 큰 텐서의 `ndim`에 맞도록 작은 텐서에 (브로드캐스팅 축이라고 부르는) 축이 추가됨\n",
    "2. 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**브로드 캐스팅의 예**\n",
    "\n",
    "- `X`의 크기 : `(32, 10)`\n",
    "- `y`의 크기 : `(10, )`  \n",
    "  \n",
    "  \n",
    "- 먼저 `y`에 비어 있는 첫 번째 축을 추가하여 크기를 `(1, 10)`으로 만든다.\n",
    "- 그런 다음 `y`를 이 축에 32번 반복하면 텐서 `Y`의 크기는 `(32, 10)`이 된다.  \n",
    "(`Y[i, :] == y for i in range(0, 32)`)\n",
    "- 이제 X와 Y의 크기가 같으므로 더할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<r>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**벡터와 행렬의 덧셈 연산 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2 # x는 2D 넘파이 배열\n",
    "    assert len(y.shape) == 1 # y는 넘파이 벡터\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "            \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**크기가 다른 두 텐서에 브로드캐스팅으로 원소별 `maximum` 연산을 적용하는 예제**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3, 32, 10)\n",
      "(32, 10)\n",
      "(64, 3, 32, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.random((64, 3, 32, 10)) # x는 (64, 3, 32, 10) 크기의 랜덤 텐서\n",
    "y = np.random.random((32, 10)) # y는 (32, 10) 크기의 랜덤 텐서\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "z = np.maximum(x, y) # 출력 z의 크기는 x와 동일하게 (64, 3, 32, 10)이다.\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 텐서 점곱 (tensor product)\n",
    "\n",
    "- 넘파이, 케라스, 씨아노, 텐서플로에서 **원소별 곱셈**은 `*` 연산자를 사용  \n",
    "  \n",
    "  \n",
    "- 넘파이와 케라스는 **점곱 연산**에 `dot` 연산자를 사용\n",
    "- 텐서플로에서의 점곱 연산은 `tf.matmul(x, y)` 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2개의 벡터 x와 y의 점곱 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1 # x : 넘파이 벡터\n",
    "    assert len(y.shape) == 1 # y : 넘파이 벡터\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    \n",
    "    z = 0.\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "        \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 벡터의 점곱은 스칼라가 되므로 원소 개수가 같은 벡터끼리 점곱이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**행렬 x와 벡터 y 사이의 점곱 구현**\n",
    "\n",
    "- y와 x의 행 사이에서 점곱이 일어나므로 벡터가 반환된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2 # x : 넘파이 행렬\n",
    "    assert len(y.shape) == 1 # y : 넘파이 벡터\n",
    "    assert x.shape[1] == y.shape[0] # x의 두 번째 차원이 y의 첫 번째 차원과 같아야 한다.\n",
    "    \n",
    "    z = np.zeros(x.shape[0]) # x의 행과 같은 크기의 0이 채워진 벡터를 만든다.\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] = x[i,j] * y[j]\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**행렬-벡터 점곱과 벡터-벡터 점곱 사이의 관계**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i,:], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**dot 연산의 교환 법칙**\n",
    "\n",
    "- 두 텐서 중 하나라도 `ndim`이 1보다 크면 dot 연산에 교환 법칙이 성립되지 않는다.\n",
    "\n",
    "```python\n",
    "dot(x, y) != dot(y, x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**점곱 연산 일반화**\n",
    "\n",
    "- `x.shape[1] == y.shape[0]` 일 때 두 행렬 x와 y의 점곱(`dot(x,y)`)이 성립된다.\n",
    "- x의 열과 y의 행 사이 벡터 점곱으로 인해 `(x.shape[0], y.shape[1])` 크기의 행렬이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2 # x : 넘파이 행렬\n",
    "    assert len(y.shape) == 2 # y : 넘파이 행렬\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    z = np.zeros((x.shape[0], y.shape[1]))\n",
    "    \n",
    "    for i in range(x.shape[0]): # x의 행 반복\n",
    "        for j in range(y.shape[1]): # y의 열 반복\n",
    "            row_x = x[i,:]\n",
    "            column_y = y[:, j]\n",
    "            z[i,j] = naive_vector_dot(row_x, column_y)\n",
    "            \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/img_2-5.jpg\" width=\"300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x, y, z는 직사각형 모양으로 그려져 있음\n",
    "- x의 행 벡터와 y의 열 벡터가 같은 크기여야 하므로 자동으로 x의 너비는 y의 높이와 동일해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 텐서 크기 변환 (tensor reshaping)\n",
    "\n",
    "```python\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "```\n",
    "\n",
    "- 텐서의 크기를 변환한다 = 특정 크기에 맞게 열과 행을 재배열한다\n",
    "- 크기가 변환된 텐서는 원래 텐서와 원소 개수가 동일하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "              [2., 3.],\n",
    "              [4., 5.]])\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [5.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [3., 4., 5.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((2,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**전치(transposition)**\n",
    "\n",
    "- 행렬의 전치는 행과 열을 바꾸는 것을 의미\n",
    "- `x[i, :]` $\\rightarrow$ `x[:, i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 20)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 텐서 연산의 기하학적 해성\n",
    "\n",
    "생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 딥러닝의 기하학적 해석\n",
    "\n",
    "생략"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
