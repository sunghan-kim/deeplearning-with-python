{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 신경망의 수학적 구성 요소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 신경망의 엔진: 그래디언트 기반 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**각 층의 입력 데이터 변환**\n",
    "\n",
    "```python\n",
    "output = relu(dot(W, input) + b)\n",
    "```\n",
    "\n",
    "\n",
    "- 이 식에서 텐서 `W`와 `b`\n",
    "  - 층의 속성\n",
    "  - `W` : 가중치(weight) 또는 훈련되는 파라미터(trainable parameter)\n",
    "  - `b` : 편향 (bias)\n",
    "  - 이런 가중치에는 훈련 데이터를 신경망에 노출시켜서 학습된 정보가 담겨 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**무작위 초기화(random initialization)**\n",
    "\n",
    "- 초기에는 가중치 행렬이 작은 난수로 채워져 있음\n",
    "- 피드백 신호에 기초하여 가중치가 점진적으로 조정될 것\n",
    "- 이런 점진적인 조정 또는 **훈련(training)**이 머신 러닝 학습의 핵심이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**훈련 반복 루프 (training loop)**\n",
    "\n",
    "- 훈련은 다음과 같은 훈련 반복 루프 안에서 일어난다.\n",
    "- 필요한 만큼 반복 루프 안에서 이런 단계가 반복됨  \n",
    "  \n",
    "  \n",
    "1. 훈련 샘플 x와 이에 상응하는 타깃 y의 배치를 추출\n",
    "2. x를 사용하여 네트워크를 실행하고(정방향 패스(forward pass) 단계), 예측 y_pred를 구함\n",
    "3. y_pred와 y의 차이를 측정하여 이 배치에 대한 네트워크의 손실을 계산\n",
    "4. 배치에 대한 손실이 조금 감소되도록 네트워크의 모든 가중치를 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4단계: 가중치의 업데이트**\n",
    "\n",
    "- 개별적인 가중치 값이 있을 때 값이 증가해야 할지 감소해야 할지, 또 얼만큼 업데이트해야 할 지 알 수 있을까?  \n",
    "  \n",
    "  \n",
    "1. 네트워크 가중치 행렬의 원소를 모두 고정하고 관심 있는 하나만 다른 값을 적용\n",
    "  - 이 가중치의 초깃값이 0.3이라고 가정\n",
    "  - 배치 데이터를 정방향 패스에 통과시킴 $\\Rightarrow$ 네트워크의 손실이 0.5가 나옴\n",
    "  - 이 가중치 값을 0.35로 변경하고 다시 정방향 패스를 실행 $\\Rightarrow$ 네트워크 손실이 0.6으로 증가  \n",
    "  (가중치 증가 $\\Rightarrow$ 손실 증가)\n",
    "  - 가중치 값을 0.25로 줄이고 정방향 패스 실행 $\\Rightarrow$ 네트워크 손실이 0.4로 감소  \n",
    "  (가중치 감소 $\\Rightarrow$ 손실 감소)\n",
    "  - 이 경우에 가중치를 -0.05 만큼 업데이트한 것이 손실을 줄이는 데 기여한 것으로 보임  \n",
    "  - 이런 식으로 네트워크의 모든 가중치에 반복  \n",
    "  - 이 방식은 모든 가중치 행렬의 원소마다 두 번의 정방향 패스를 계산해야 하므로 엄청나게 비효율적이다.  \n",
    "  \n",
    "  \n",
    "2. **그래디언트(gradient)** 계산\n",
    "  - 신경망에 사용된 모든 연산이 **미분 가능(differentiable)**하다는 장점을 사용하여 네트워크의 가중치에 대한 손실의 **그래디언트(gradient, 연산의 미분 결과)**를 계산하는 것이 훨씬 더 좋은 방법\n",
    "  - 그래디언트의 반대 방향으로 가중치를 이동하면 손실이 감소된다.  \n",
    "  (그래디언트 증가 $\\Rightarrow$ 가중치 감소 $\\Rightarrow$ 손실 감소)  \n",
    "  (그래디언트 감소 $\\Rightarrow$ 가중치 증가 $\\Rightarrow$ 손실 감소) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 변화율이란?\n",
    "\n",
    "**연속성의 개념**\n",
    "\n",
    "- $f(x) = y$\n",
    "  - 실수 $x$를 새로운 실수 $y$로 매핑하는 연속적이고 매끄러운 함수\n",
    "  - 이 함수가 연속적이므로 $x$를 조금 바꾸면 $y$가 조금만 변경될 것이다.\n",
    "  - 이 것이 연속성의 개념이다.  \n",
    "  \n",
    "  \n",
    "- $x$를 작은 값 $epsilon\\_x$ 만큼 증가시켰을 때 $y$가 $epsilon\\_y$ 만큼 바뀐다고 할 수 있다.\n",
    "\n",
    "$$\n",
    "f\\left( x + epsilon\\_x \\right) = y + a \\times epsilon\\_x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**변화율(derevative)**\n",
    "\n",
    "- 이 선형적인 근사는 $x$가 $p$에 충분히 가까울 때 유효하다.\n",
    "- 이 기울기를 $p$에서 $f$의 **변화율**이라고 한다.  \n",
    "  \n",
    "  \n",
    "- 이는 $a$가 음수일 때 $p$에서 양수$x$ 만큼 조금 이동하면 $f(x)$가 감소한다는 것을 의미한다.\n",
    "\n",
    "<img src=\"img/img_2-10.jpg\" width=\"300px\" />\n",
    "\n",
    "- $a$가 양수일 때는 음수 $x$ 만큼 조금 이동하면 $f(x)$ 가 감소된다.  \n",
    "  \n",
    "  \n",
    "- $a$의 절댓값(변화율의 크기)은 이런 증가나 감소가 얼마나 빠르게 일어날 지 알려준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**미분 가능**\n",
    "\n",
    "- 미분 가능하다  \n",
    "  - 변화율을 유도할 수 있다\n",
    "  - 예를 들어 매끄럽고 연속적인 함수 일 때 이 함수는 미분 가능하다고 한다.\n",
    "  \n",
    "  \n",
    "- 모든 미분 가능한 함수 $f(x)$ 에 대해 $x$의 값을 $f$의 국부적인 선형 근사인 그 지점의 기울기로 매핑하는 변화율 함수 $f'(x)$가 존재한다.\n",
    "  - $cos(x)$의 변화율 $\\Rightarrow$ $-sin(x)$\n",
    "  - $f(x) = a \\times x$의 변화율 $\\Rightarrow$ $f'(x) = a$  \n",
    "  \n",
    "  \n",
    "- $f(x)$ 를 최소화하기 위해 $epsilon\\_x$ 만큼 $x$를 업데이트하고 싶을 때 $f$의 변화율을 알고 있다면 해결된다.\n",
    "- 변화율 함수는 $x$가 바뀜에 따라 $f(x)$가 어떻게 바뀔지 설명해 준다.\n",
    "- $f(x)$의 값을 감소시키고 싶다면 $x$를 변화율의 방향과 반대로 조금 이동해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 텐서 연산의 변화율: 그래디언트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
